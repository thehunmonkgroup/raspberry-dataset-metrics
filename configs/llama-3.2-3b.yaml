# Configuration for Llama 3.1 AL training
model_name: "unsloth/Llama-3.2-3B-Instruct"
model_family: "llama-3.1"

# Optional overrides
per_device_train_batch_size: 4
gradient_accumulation_steps: 4
warmup_steps: 100
num_train_epochs: 3
learning_rate: 1e-4
